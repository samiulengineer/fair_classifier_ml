{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pathlib\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "plt.style.use('seaborn-white')\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import plotly.figure_factory as ff\n",
    "from plotly import tools\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset\n",
    "\n",
    " --- \n",
    "\n",
    "First we define the path to the dataset and column names. Then using Pandas library, we read the adult.csv file. To about extra space we used a sperator where we defind ``` sep = r'\\s*,\\s*' ```. Again we used a lambda function while reading the csv file to take only white and black race in the dataset. After read the dataset, we print the length of the dataset which is $ 30,940 $ and contain about $ 15 $ features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'E:/canada syntex/Github/fair_classifier_ml/data/adult.data'\n",
    "\n",
    "# defining the column name\n",
    "column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
    "                    'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "# load dataset      \n",
    "df = (pd.read_csv(data_path, names=column_names, \n",
    "                    na_values=\"?\", sep=r'\\s*,\\s*', engine='python')\n",
    "                    .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "                    \n",
    "\n",
    "print(\"Length of the dataset: \",len(df))\n",
    "print(\"The dataset shape: \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset related information\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we will explore the dataset using pandas buitin functions. First, we see the first five column to get an overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns information**\n",
    "\n",
    "Next, we will get each column information of the dataset using builtin function called info(). This function will give us:\n",
    "- Column id\n",
    "- Column name\n",
    "- Non-Null Count\n",
    "- Column data type\n",
    "\n",
    "From Dtype column, we find that we have $15$ columns where $6$ of them are integer data type and rest of them are string data type. In the non-null count, we observe that workclass, occupation, country have some null values. Lastly, we get total memory usage which is $ 3.8+ $ MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary statistics**\n",
    "\n",
    "Now we will get the full details of our dataset using builtin function called ``` describe() ```. This function gives us a summary statistics  of each column in the dataset. We pass a parameter ``` include='all' ``` to see all the column's information. Without passing the parameter, this function will give us a summary statistics containing only the integer value type columns. For numerical values it's include:\n",
    " - Total number of value\n",
    " - Average value\n",
    " - Standard deviation\n",
    " - Minimum value\n",
    " - Maximum value\n",
    " \n",
    "For string value it's include:\n",
    " - Number of unique value\n",
    " - Highest number of occurrence\n",
    " - Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check for missing value**\n",
    "\n",
    "From upper cell we see that there were some missing values in the dataset. We define a function called ``` print_missing_values() ``` to get all the missing value or null value and plot it in a bar diagram. We considered both null value and negative values. We can see that only three columns contains null values where\n",
    "- occupation = 1730\n",
    "- workclass = 1723\n",
    "- country = 482\n",
    "\n",
    "After find out the number of missing values we remove all missing value using builtin function called ``` dropna() ```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_missing_values(data):\n",
    "    data_null = pd.DataFrame(len(data) - data.notnull().sum(), columns = ['Count'])\n",
    "    data_null = data_null[data_null['Count'] > 0].sort_values(by='Count', ascending=False)\n",
    "    data_null = data_null   #/len(data) * 100\n",
    "\n",
    "    trace = go.Bar(x=data_null.index, y=data_null['Count'], marker=dict(color='#c0392b'),\n",
    "              name = 'At least one missing value', opacity=0.9)\n",
    "    layout = go.Layout(barmode='group', title='Column with missing values in the dataset', showlegend=True,\n",
    "                   legend=dict(orientation=\"h\"), yaxis=dict(title='Number of missing value'))\n",
    "    fig = go.Figure([trace], layout=layout)\n",
    "    py.iplot(fig)\n",
    "\n",
    "print('Number total of rows : '+str(df.shape[0]))\n",
    "print_missing_values(df)\n",
    "df = df.dropna()    # remove missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check unique values in the dataset**\n",
    "\n",
    "The upper cells did not give us unique value for all the columns in the dataset. So, we used another builtin function called  ```nunique()``` to gives us unique value for all the features. Here we can see that **fnlwgt** got the highest unique values. We can also see that target columns has only two unique values. That means our dataset require binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bar chart plot**\n",
    "\n",
    "Now we will see the histogram of the columns that has numerical values. It will give us an idea about the data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = df.hist(bins=10, figsize=(10, 15), grid=False, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unbalanced dataset\n",
    "\n",
    "---\n",
    "\n",
    "We will start by seeing if our dataset is unbalanced. Specifically, we mean unbalanced in terms of the sensitive attributes. Looking at below figure, we have the breakdown of the population by race and sex. You can see that we do have an unbalanced dataset. The first chart shows that 86% of our population is white. Similarly, 68% of the population is male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(y_var, data):\n",
    "    val = data[y_var]\n",
    "\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.rcParams.update({'font.size': 13})\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "    cnt = val.value_counts().sort_values(ascending=True)\n",
    "    labels = cnt.index.values\n",
    "\n",
    "    sizes = cnt.values\n",
    "    colors = sns.color_palette(\"PuBu\", len(labels))\n",
    "\n",
    "    #------------COUNT-----------------------\n",
    "    ax1.barh(cnt.index.values, cnt.values, color=colors)\n",
    "    ax1.set_title('Count plot of '+y_var)\n",
    "\n",
    "    #------------PERCENTAGE-------------------\n",
    "    ax2.pie(sizes, labels=labels, colors=colors,autopct='%1.0f%%', shadow=True, startangle=130)\n",
    "    ax2.axis('equal')\n",
    "    ax2.set_title('Distribution of '+y_var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'race'\n",
    "target_distribution(y_var=var, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'sex'\n",
    "target_distribution(y_var=var, data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining protected features\n",
    "\n",
    "---\n",
    "\n",
    "Now, we will need to define the protected features. We do this by creating binary variables using the sensitive attributes. We define the variable so that 1 represents a privileged group and 0 represents an unprivileged group. Typically, the unprivileged group will have faced historical injustice in the past. In other words, it is the group that will most likely face unfair decisions from a biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fair = df[['race','sex']]\n",
    "\n",
    "#Define protected variables \n",
    "df_fair['priv_race'] = [1 if r=='White' else 0 for r in df_fair['race']]\n",
    "df_fair['priv_sex'] = [1 if s=='Male' else 0 for s in df_fair['sex']]\n",
    "\n",
    "#Define target variable \n",
    "df_fair['target'] =  [1 if y == '>50K'else 0 for y in df['target']]\n",
    "\n",
    "df_fair.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prevelance\n",
    "\n",
    "--- \n",
    "\n",
    "For a target variable, prevalence is the proportion of the positive cases to overall cases. Where a positive case is when the target variable has a value of 1. Our dataset has an overall prevalence of 24.8%. That is roughly 1/4 of the people in our dataset earn above $50K. We can also use prevalence as a fairness metric.\n",
    "\n",
    "We do this by calculating prevalence for our different privileged (1) and unprivileged (0) groups. We can see these values in Table 1 below. Notice that the prevalence is much higher for the privileged groups. If fact, a male you are nearly 3 times as likely to earn above $50K than a female."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate prevelance\n",
    "prev = df_fair['target'].mean()\n",
    "prev_race = df_fair.groupby('priv_race')['target'].mean()\n",
    "prev_sex = df_fair.groupby('priv_sex')['target'].mean()\n",
    "prev_comb = df_fair.groupby(['priv_race','priv_sex'])['target'].mean()\n",
    "\n",
    "prev_race = prev_race*100\n",
    "prev_sex = prev_sex*100\n",
    "prev_comb = prev_comb*100\n",
    "\n",
    "print(\"________________________________\")\n",
    "print(\"Table: 1\")\n",
    "print(\"\\t1 \\t   0\")\n",
    "print(\"Race  {:.2f}% \\t {:.2f}%\".format(prev_race[1], prev_race[0]))\n",
    "print(\"Sex   {:.2f}% \\t {:.2f}%\".format(prev_sex[1], prev_sex[0]))\n",
    "print(\"________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can go further by calculating the prevalence at the intersection of the protected features. We can see these values in Table 2. The top left corner gives the prevalence if you are in both privileged groups (i.e sex = 1 & race = 1). Similarly, the bottom right gives the prevalence if you are in neither privileged group (i.e sex = 0 & race = 0). This tells us that white males are over 4 times as likely to earn above $50K than non-white females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"________________________________\")\n",
    "print(\"Table: 2\")\n",
    "\n",
    "print(prev_comb)\n",
    "\n",
    "print(\"________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proxy Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target variable \n",
    "y = [1 if y == '>50K' else 0 for y in df['target']]\n",
    "\n",
    "#Model features\n",
    "X = df[['age','education_num','hours_per_week']]\n",
    "X['marital_status'] = [1 if x=='Married-civ-spouse' else 0 for x in df['marital_status']] \n",
    "X['country'] = [1 if x=='United-States' else 0 for x in df['country']] \n",
    "\n",
    "occ_groups = {\n",
    "    'Priv-house-serv':0,'Other-service':0,'Handlers-cleaners':0,\n",
    "    'Farming-fishing':1,'Machine-op-inspct':1,'Adm-clerical':1,\n",
    "    'Transport-moving':2,'Craft-repair':2,'Sales':2,\n",
    "    'Armed-Forces':3,'Tech-support':3,'Protective-serv':3,\n",
    "    'Prof-specialty':4,'Exec-managerial':4}\n",
    "\n",
    "X['occupation'] = [occ_groups[x] for x in df['occupation']]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mutual information \n",
    "\n",
    "#Calcualte mutual information\n",
    "mut_race = mutual_info_classif(X,df_fair['priv_race'],discrete_features=[1,3,4,5])\n",
    "mut_sex = mutual_info_classif(X,df_fair['priv_sex'],discrete_features=[1,3,4,5])\n",
    "\n",
    "\n",
    "#Plot mutual information\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "labels = ['age', 'education_num', 'hours_per_week', 'marital_status',\n",
    "       'country', 'occupation']\n",
    "x = np.arange(6) # lenth of the labels\n",
    "width = 0.4\n",
    "plt.bar(x-width/2,height= mut_race,width=width,label='Race')\n",
    "plt.bar(x+width/2,height= mut_sex,width=width,label='Sex')\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.ylabel('Mutual Information',size=15)\n",
    "plt.xticks(ticks=x,labels=labels)\n",
    "\n",
    "plt.show()\n",
    "# plt.savefig(output_path+\"Mutual_information.png\", dpi=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitive features vs other features\n",
    "\n",
    "---\n",
    "\n",
    "In this section, we will see the data distribution of each columns based on two sensitive features race and sex. First we calculate the frequency of the sensitive features. Based on the frequency we get $ 62.7409\\% $ of male white in our dataset. So, in our dataset, the perpetrator is  white males."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Frequency'] = 1\n",
    "freq_target = df[['sex', 'race', 'Frequency']]\n",
    "del df['Frequency']\n",
    "freq_target = freq_target.groupby(by=['sex', 'race']).count() / len(df)\n",
    "print(freq_target.sort_values(by='Frequency', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histo(data, col, Y_columns):\n",
    "    df = data.copy()\n",
    "    fig, axs = plt.subplots(1,2,figsize=(20,6))\n",
    "    \n",
    "    for i in range(0,2):\n",
    "        cnt = []; y_col = Y_columns[i]\n",
    "        Y_values = df[y_col].dropna().drop_duplicates().values\n",
    "        for val in Y_values:\n",
    "            cnt += [df[df[y_col] == val][col].values]\n",
    "        bins = df[col].nunique()\n",
    "\n",
    "        axs[i].hist(cnt, bins=bins, stacked=True)\n",
    "        axs[i].legend(Y_values,loc='upper right')\n",
    "        axs[i].set_title(\"Histogram of the \"+col+\" column by \"+y_col)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_columns = ['sex', 'race']\n",
    "plot_histo(df, col='age',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='workclass',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='education',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='education_num',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='marital_status',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='occupation',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='relationship',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='capital_gain',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='capital_loss',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='hours_per_week',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='country',Y_columns=Y_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_histo(df, col='target',Y_columns=Y_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b071dc9d7bd7f4957263bd15e9b479697ca69f15dcdb44ae4af94402ab3b7ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
