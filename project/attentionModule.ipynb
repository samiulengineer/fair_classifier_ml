{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn: 1.1.2\n",
      "pandas: 1.4.3\n",
      "tensorflow: 2.10.0\n"
     ]
    }
   ],
   "source": [
    "# HIDE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", palette=[sns.color_palette('muted')[i] for i in [0,2]], \n",
    "        color_codes=True, context=\"talk\")\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils.class_weight import compute_class_weight  # Estimate class weights for unbalanced datasets\n",
    "\n",
    "# import keras as ke\n",
    "# import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "create_gif = False\n",
    "\n",
    "print(f\"sklearn: {sk.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"tensorflow: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ICU_data(path):\n",
    "    column_names = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', \n",
    "                    'marital_status', 'occupation', 'relationship', 'race', 'sex', \n",
    "                    'capital_gain', 'capital_loss', 'hours_per_week', 'country', 'target']\n",
    "    input_data = (pd.read_csv(path, names=column_names, \n",
    "                              na_values=\"?\", sep=r'\\s*,\\s*', engine='python') # here seperator -- 0 or more whitespace then , then 0 or more whitespace --\n",
    "                              .loc[lambda df: df['race'].isin(['White', 'Black'])])\n",
    "\n",
    "    input_data = input_data.dropna()    # remove missing value\n",
    "    # sensitive attributes; we identify 'race' and 'sex' as sensitive attributes\n",
    "    sensitive_attribs = ['race', 'sex']\n",
    "    Z = (input_data.loc[:, sensitive_attribs]\n",
    "         .assign(race=lambda df: (df['race'] == 'White').astype(int),\n",
    "                 sex=lambda df: (df['sex'] == 'Male').astype(int)))\n",
    "\n",
    "    # targets; 1 when someone makes over 50k , otherwise 0\n",
    "    y = (input_data['target'] == '>50K').astype(int) # Cast a pandas object to a specified dtype dtype.\n",
    "\n",
    "    # features; note that the 'target' and sentive attribute columns are dropped\n",
    "    X = (input_data\n",
    "         .drop(columns=['target', 'race', 'sex'])\n",
    "         .fillna('Unknown')   # The fillna() function is used to fill NA/NaN values using the specified method\n",
    "         .pipe(pd.get_dummies, drop_first=True)) # Use .pipe when chaining together functions that expect Series, DataFrames or GroupBy objects.\n",
    "                                                 # pd.get_dummies=Convert categorical variable into dummy/indicator variables\n",
    "                                                 # drop_first: bool function(default False) Whether to get k-1 dummies out of k categorical levels by removing the first level.\n",
    "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
    "    print(f\"targets y: {y.shape[0]} samples\")\n",
    "    print(f\"sensitives Z: {Z.shape[0]} samples, {Z.shape[1]} attributes\")\n",
    "    return X, y, Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features X: 28750 samples, 89 attributes\n",
      "targets y: 28750 samples\n",
      "sensitives Z: 28750 samples, 2 attributes\n"
     ]
    }
   ],
   "source": [
    "# load ICU data set         \n",
    "X, y, Z = load_ICU_data('E:/canada syntex/Github/fair_classifier_ml/data/adult.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "x_columns = X.columns\n",
    "z_columns = Z.columns\n",
    "print(len(x_columns))\n",
    "print(len(z_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2b071dc9d7bd7f4957263bd15e9b479697ca69f15dcdb44ae4af94402ab3b7ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
